// ========================================
// DBF READER SERVICE
// ========================================

import * as fs from 'fs-extra';
import * as path from 'path';
import { PrismaClient } from '@prisma/client';
import { FileProcessingStatus } from '@/types';
import { logInfo, logError } from '@/utils/logger';

export interface DBFField {
  name: string;
  type: string;
  length: number;
  decimalPlaces: number;
}

export interface DBFHeader {
  version: number;
  year: number;
  month: number;
  day: number;
  recordCount: number;
  headerLength: number;
  recordLength: number;
  fields: DBFField[];
}

export interface DBFRecord {
  [key: string]: any;
}

export interface DBFParseResult {
  header: DBFHeader;
  records: DBFRecord[];
  schema: DBFField[];
}

export class DBFReaderService {
  private prisma: PrismaClient;

  constructor(prisma: PrismaClient) {
    this.prisma = prisma;
  }

  /**
   * ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå DBF
   */
  async parseDBFFile(filePath: string): Promise<DBFParseResult> {
    try {
      logInfo(`üîç ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå DBF: ${path.basename(filePath)}`);
      
      // ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô Buffer
      const buffer = await fs.readFile(filePath);
      
      // ‡πÅ‡∏¢‡∏Å header ‡πÅ‡∏•‡∏∞ records
      const header = this.parseHeader(buffer);
      const records = this.parseRecords(buffer, header);
      
      logInfo(`‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå DBF ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: ${header.recordCount} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£, ${header.fields.length} ‡∏ü‡∏¥‡∏•‡∏î‡πå`);
      
      return {
        header,
        records,
        schema: header.fields
      };
    } catch (error) {
      logError('Error parsing DBF file', error as Error);
      throw new Error(`‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå DBF ‡πÑ‡∏î‡πâ: ${(error as Error).message}`);
    }
  }

  /**
   * ‡∏≠‡πà‡∏≤‡∏ô header ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå DBF
   */
  private parseHeader(buffer: Buffer): DBFHeader {
    // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
    if (buffer.length < 32) {
      throw new Error('‡πÑ‡∏ü‡∏•‡πå DBF ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ');
    }

    // ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• header ‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô DBF
    const version = buffer[0] || 0;
    const year = (buffer[1] || 0) + 1900; // DBF ‡πÉ‡∏ä‡πâ‡∏õ‡∏µ 1900 ‡πÄ‡∏õ‡πá‡∏ô‡∏ê‡∏≤‡∏ô
    const month = buffer[2] || 0;
    const day = buffer[3] || 0;
    const recordCount = buffer.readUInt32LE(4);
    const headerLength = buffer.readUInt16LE(8);
    const recordLength = buffer.readUInt16LE(10);

    // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á header
    if (headerLength < 32 || recordLength < 1) {
      throw new Error('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• header ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå DBF ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á');
    }

    // ‡∏≠‡πà‡∏≤‡∏ô field definitions
    const fields: DBFField[] = [];
    let offset = 32; // ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å header ‡∏´‡∏•‡∏±‡∏Å

    while (offset < headerLength - 1) {
      // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö field terminator (0x0D)
      if (buffer[offset] === 0x0D) {
        break;
      }

      // ‡∏≠‡πà‡∏≤‡∏ô field name (11 bytes, null-terminated)
      const fieldName = buffer.toString('ascii', offset, offset + 11).replace(/\0/g, '');
      
      // ‡∏≠‡πà‡∏≤‡∏ô field type (1 byte)
      const fieldType = String.fromCharCode(buffer[offset + 11] || 0);
      
      // ‡∏≠‡πà‡∏≤‡∏ô field length ‡πÅ‡∏•‡∏∞ decimal places
      const fieldLength = buffer[offset + 16] || 0;
      const decimalPlaces = buffer[offset + 17] || 0;

      // ‡πÄ‡∏û‡∏¥‡πà‡∏° field ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á
      if (fieldName.trim()) {
        fields.push({
          name: fieldName.trim(),
          type: fieldType,
          length: fieldLength,
          decimalPlaces: decimalPlaces
        });
      }

      offset += 32; // ‡πÅ‡∏ï‡πà‡∏•‡∏∞ field definition ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î 32 bytes
    }

    return {
      version,
      year,
      month,
      day,
      recordCount,
      headerLength,
      recordLength,
      fields
    };
  }

  /**
   * ‡∏≠‡πà‡∏≤‡∏ô records ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå DBF
   */
  private parseRecords(buffer: Buffer, header: DBFHeader): DBFRecord[] {
    const records: DBFRecord[] = [];
    let offset = header.headerLength;

    for (let i = 0; i < header.recordCount; i++) {
      // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö record marker (0x20 = active, 0x2A = deleted)
      const recordMarker = buffer[offset];
      
      if (recordMarker === 0x20) { // Active record
        const record: DBFRecord = {};
        let fieldOffset = offset + 1; // ‡∏Ç‡πâ‡∏≤‡∏° record marker

        for (const field of header.fields) {
          // ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° field length
          const fieldData = buffer.toString('ascii', fieldOffset, fieldOffset + field.length).trim();
          
          // ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° field type
          let value: any = fieldData;
          
          switch (field.type.toUpperCase()) {
            case 'N': // Numeric
              if (fieldData) {
                value = parseFloat(fieldData);
                if (isNaN(value)) {
                  value = fieldData; // ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô string ‡∏ñ‡πâ‡∏≤‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
                }
              }
              break;
              
            case 'D': // Date (YYYYMMDD)
              if (fieldData && fieldData.length === 8) {
                const year = parseInt(fieldData.substring(0, 4));
                const month = parseInt(fieldData.substring(4, 6)) - 1;
                const day = parseInt(fieldData.substring(6, 8));
                if (!isNaN(year) && !isNaN(month) && !isNaN(day)) {
                  value = new Date(year, month, day).toISOString();
                }
              }
              break;
              
            case 'L': // Logical (T/F, Y/N, 1/0)
              if (fieldData) {
                const upper = fieldData.toUpperCase();
                value = upper === 'T' || upper === 'Y' || upper === '1';
              }
              break;
              
            default: // Character ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô‡πÜ
              value = fieldData;
          }

          record[field.name] = value;
          fieldOffset += field.length;
        }

        records.push(record);
      }

      offset += header.recordLength;
    }

    return records;
  }

  /**
   * ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBF records ‡∏•‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
   */
  async saveDBFRecordsToDatabase(
    fileId: string, 
    records: DBFRecord[], 
    schema: DBFField[]
  ): Promise<{ success: boolean; savedCount: number; error?: string }> {
    try {
      logInfo(`üíæ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å ${records.length} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ DBF ‡∏•‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå ${fileId}`);

      // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
      const uploadRecord = await this.prisma.uploadRecord.findUnique({
        where: { id: fileId }
      });

      if (!uploadRecord) {
        throw new Error(`‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå ID: ${fileId} ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•`);
      }

      // ‡∏•‡∏ö records ‡πÄ‡∏î‡∏¥‡∏° (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥
      await this.prisma.dBF_Record.deleteMany({
        where: { fileId }
      });

      // ‡∏™‡∏£‡πâ‡∏≤‡∏á records ‡πÉ‡∏´‡∏°‡πà
      const dbfRecords = records.map((record, index) => ({
        fileId,
        recordIndex: index,
        data: JSON.stringify(record)
      }));

      // ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏ö‡∏ö batch
      const savedRecords = await this.prisma.dBF_Record.createMany({
        data: dbfRecords
      });

      // ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏à‡∏≥‡∏ô‡∏ß‡∏ô records ‡πÉ‡∏ô UploadRecord
      await this.prisma.uploadRecord.update({
        where: { id: fileId },
        data: {
          totalRecords: records.length,
          status: FileProcessingStatus.SUCCESS,
          metadata: JSON.stringify({
            ...JSON.parse(uploadRecord.metadata || '{}'),
            dbfSchema: schema,
            recordCount: records.length,
            processedAt: new Date().toISOString()
          })
        }
      });

      logInfo(`‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å DBF records ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: ${savedRecords.count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£`);

      return {
        success: true,
        savedCount: savedRecords.count
      };

    } catch (error) {
      logError('Error saving DBF records to database', error as Error);
      return {
        success: false,
        savedCount: 0,
        error: (error as Error).message
      };
    }
  }

  /**
   * ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBF records ‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
   */
  async getDBFRecordsFromDatabase(
    fileId: string, 
    limit: number = 100, 
    offset: number = 0
  ): Promise<{ records: DBFRecord[]; total: number; schema?: DBFField[] | undefined }> {
    try {
      // ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• upload record ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π schema
      const uploadRecord = await this.prisma.uploadRecord.findUnique({
        where: { id: fileId }
      });

      if (!uploadRecord) {
        throw new Error(`‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå ID: ${fileId}`);
      }

      // ‡∏î‡∏∂‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô records ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
      const total = await this.prisma.dBF_Record.count({
        where: { fileId }
      });

      // ‡∏î‡∏∂‡∏á records ‡∏ï‡∏≤‡∏° limit ‡πÅ‡∏•‡∏∞ offset
      const dbfRecords = await this.prisma.dBF_Record.findMany({
        where: { fileId },
        orderBy: { recordIndex: 'asc' },
        take: limit,
        skip: offset
      });

      // ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô objects
      const records: DBFRecord[] = dbfRecords.map(dbfRecord => 
        JSON.parse(dbfRecord.data)
      );

      // ‡∏î‡∏∂‡∏á schema ‡∏à‡∏≤‡∏Å metadata
      let schema: DBFField[] | undefined;
      if (uploadRecord.metadata) {
        try {
          const metadata = JSON.parse(uploadRecord.metadata);
          schema = metadata.dbfSchema;
        } catch {
          // ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ parse metadata ‡πÑ‡∏î‡πâ
        }
      }

      return {
        records,
        total,
        schema: schema || undefined
      };

    } catch (error) {
      logError('Error getting DBF records from database', error as Error);
      throw error;
    }
  }

  /**
   * ‡∏•‡∏ö DBF records ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
   */
  async deleteDBFRecords(fileId: string): Promise<boolean> {
    try {
      await this.prisma.dBF_Record.deleteMany({
        where: { fileId }
      });
      
      logInfo(`üóëÔ∏è ‡∏•‡∏ö DBF records ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå ${fileId} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à`);
      return true;
    } catch (error) {
      logError('Error deleting DBF records', error as Error);
      return false;
    }
  }

  /**
   * ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå DBF
   */
  async getDBFProcessingStatus(fileId: string): Promise<{
    isProcessed: boolean;
    recordCount: number;
    processedAt?: string | undefined;
    schema?: DBFField[] | undefined;
  }> {
    try {
      const uploadRecord = await this.prisma.uploadRecord.findUnique({
        where: { id: fileId }
      });

      if (!uploadRecord) {
        return { isProcessed: false, recordCount: 0 };
      }

      const recordCount = await this.prisma.dBF_Record.count({
        where: { fileId }
      });

      let processedAt: string | undefined;
      let schema: DBFField[] | undefined;

      if (uploadRecord.metadata) {
        try {
          const metadata = JSON.parse(uploadRecord.metadata);
          processedAt = metadata.processedAt;
          schema = metadata.dbfSchema;
        } catch {
          // ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ parse metadata ‡πÑ‡∏î‡πâ
        }
      }

      return {
        isProcessed: recordCount > 0,
        recordCount,
        processedAt: processedAt || undefined,
        schema: schema || undefined
      };

    } catch (error) {
      logError('Error getting DBF processing status', error as Error);
      return { isProcessed: false, recordCount: 0 };
    }
  }

  /**
   * ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBF records ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OPD
   */
  async getAllDBFRecordsFromDatabaseForOPD(fileId: string): Promise<DBFRecord[]> {
    try {
      const dbfRecords = await this.prisma.dBF_Record.findMany({
        where: { fileId },
        orderBy: { recordIndex: 'asc' }
      });

      // ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô objects
      const records: DBFRecord[] = dbfRecords.map(dbfRecord => 
        JSON.parse(dbfRecord.data)
      );

      logInfo(`üìä ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBF records ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OPD: ${records.length} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£`);
      return records;

    } catch (error) {
      logError('Error getting all DBF records from database for OPD', error as Error);
      throw error;
    }
  }

  /**
   * ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBF records ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö IPD
   */
  async getAllDBFRecordsFromDatabaseForIPD(fileId: string): Promise<DBFRecord[]> {
    try {
      const dbfRecords = await this.prisma.dBF_Record.findMany({
        where: { fileId },
        orderBy: { recordIndex: 'asc' }
      });

      // ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô objects
      const records: DBFRecord[] = dbfRecords.map(dbfRecord => 
        JSON.parse(dbfRecord.data)
      );

      logInfo(`üìä ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBF records ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö IPD: ${records.length} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£`);
      return records;

    } catch (error) {
      logError('Error getting all DBF records from database for IPD', error as Error);
      throw error;
    }
  }

  /**
   * ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå DBF ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
   */
  async createDBFFileFromRecords(
    records: DBFRecord[], 
    outputPath: string, 
    _originalFileName: string
  ): Promise<void> {
    try {
      logInfo(`üìù ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå DBF: ${path.basename(outputPath)}`);

      // ‡∏™‡∏£‡πâ‡∏≤‡∏á schema ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏£‡∏Å (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
      let schema: DBFField[] = [];
      if (records.length > 0) {
        const firstRecord = records[0];
        if (firstRecord) {
          schema = Object.keys(firstRecord).map(fieldName => {
            const value = firstRecord[fieldName];
            const valueStr = String(value || '');
            
            return {
              name: fieldName,
              type: 'C', // Character type ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
              length: Math.max(valueStr.length, 10), // ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ 10
              decimalPlaces: 0
            };
          });
        }
      }

      // ‡∏™‡∏£‡πâ‡∏≤‡∏á header
      const header = this.createDBFHeader(records.length, schema);
      
      // ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå DBF
      const buffer = this.createDBFBuffer(header, records, schema);
      
      // ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå
      await fs.writeFile(outputPath, buffer);
      
      logInfo(`‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå DBF ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: ${path.basename(outputPath)} (${records.length} records)`);

    } catch (error) {
      logError('Error creating DBF file from records', error as Error);
      throw new Error(`‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå DBF ‡πÑ‡∏î‡πâ: ${(error as Error).message}`);
    }
  }

  /**
   * ‡∏™‡∏£‡πâ‡∏≤‡∏á DBF header
   */
  private createDBFHeader(recordCount: number, fields: DBFField[]): DBFHeader {
    const now = new Date();
    const headerLength = 32 + (fields.length * 32) + 1; // 32 bytes header + field definitions + terminator
    const recordLength = fields.reduce((sum, field) => sum + field.length, 1); // +1 for deletion flag

    return {
      version: 3, // dBASE III
      year: now.getFullYear() - 1900, // DBF ‡πÉ‡∏ä‡πâ‡∏õ‡∏µ 1900 ‡πÄ‡∏õ‡πá‡∏ô‡∏ê‡∏≤‡∏ô
      month: now.getMonth() + 1,
      day: now.getDate(),
      recordCount,
      headerLength,
      recordLength,
      fields
    };
  }

  /**
   * ‡∏™‡∏£‡πâ‡∏≤‡∏á DBF buffer
   */
  private createDBFBuffer(header: DBFHeader, records: DBFRecord[], fields: DBFField[]): Buffer {
    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î buffer
    const headerSize = header.headerLength;
    const recordSize = header.recordLength;
    const totalSize = headerSize + (records.length * recordSize);
    
    const buffer = Buffer.alloc(totalSize);
    let offset = 0;

    // ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô header
    buffer[offset++] = header.version;
    buffer[offset++] = header.year;
    buffer[offset++] = header.month;
    buffer[offset++] = header.day;
    buffer.writeUInt32LE(header.recordCount, offset);
    offset += 4;
    buffer.writeUInt16LE(header.headerLength, offset);
    offset += 2;
    buffer.writeUInt16LE(header.recordLength, offset);
    offset += 2;
    
    // ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô reserved bytes (10 bytes)
    for (let i = 0; i < 10; i++) {
      buffer[offset++] = 0;
    }
    
    // ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô field definitions
    for (const field of fields) {
      // Field name (11 bytes)
      const nameBuffer = Buffer.from(field.name.padEnd(11, '\0'));
      nameBuffer.copy(buffer, offset);
      offset += 11;
      
      // Field type (1 byte)
      buffer[offset++] = field.type.charCodeAt(0);
      
      // Reserved (4 bytes)
      for (let i = 0; i < 4; i++) {
        buffer[offset++] = 0;
      }
      
      // Field length (1 byte)
      buffer[offset++] = field.length;
      
      // Decimal places (1 byte)
      buffer[offset++] = field.decimalPlaces;
      
      // Reserved (14 bytes)
      for (let i = 0; i < 14; i++) {
        buffer[offset++] = 0;
      }
    }
    
    // Header terminator
    buffer[offset++] = 0x0D;
    
    // ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô records
    for (const record of records) {
      // Deletion flag
      buffer[offset++] = 0x20; // Space = not deleted
      
      // Record data
      for (const field of fields) {
        const value = record[field.name] || '';
        const valueStr = String(value);
        const paddedValue = valueStr.padEnd(field.length, ' ');
        const valueBuffer = Buffer.from(paddedValue.substring(0, field.length));
        valueBuffer.copy(buffer, offset);
        offset += field.length;
      }
    }

    return buffer;
  }
}
